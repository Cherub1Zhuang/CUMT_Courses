# 引言

## 局部性

局部性原理表明了在任何时间内，程序访问的只是地址空间相对较小的一部分内容。以下是两种不同类型的局部性：

* **时间局部性**：如果某个数据项杯访问，那么在不久的将来它可能再次被访问。就如刚拿了一本书到书桌上查阅，那么很可能你会很快的再次查阅它
* **空间局部性**：如果某个数据项被访问，它地址相邻的数据项可能很快被访问。

> 时间局部性：某个数据项再被访问之后可能很快被再次访问的特性。
>
> 空间局部性：某个数据项再被访问之后，与其地址相邻的数据项可能很快被访问的特性

## 存储器结构

我们可以利用局部性原理将计算机存储器组织成为**存储器层次结构**。存储器层次结构由不同速度和容量的多级存储器构成。快速存储器每比特的成本要比慢速存储器高很多，因而通常它们的容量也比较小。

* 存储器层次结构：一种由多存储器层次组成的结构，存储器的容量和访问时间随着离处理器距离的增加而增加。

存储器层次结构可以由多层构成，但是数据每次只能在相邻的两个层次之间进行复制。因此我们将注意力重点集中在连个层次上。高层的存储器靠近处理器，比底层存储器容量小但访问速度更快，这是因为它采用了成本较高的技术来实现。我们将一个两级层次结构中存储信息交换的最小单元称为**块**或**行**。

![存储器分层](https://kuangstudy.oss-cn-beijing.aliyuncs.com/bbs/2021/04/17/kuangstudybe776f5e-ab4b-4828-94be-f0a743f60ce8.png)



如果处理器需要的数据放在高层存储器中的某个块中，则称为一次**命中**。如果在高层存储器中没有找到所需要的数据，这次数据请求则称为一次**缺失**。随后访问低层存储器来寻找包含所需数据的那一块。下面介绍几个名词：

> 块或行：可存在与或不存在与cache中的信息的最小单元。
>
> 命中率：在高层存储器中找到目标数据的存储访问比例。
>
> 缺失率：在高层存储器中没有找到目标数据的存储访问比例。
>
> 命中时间：访问某存储器层次结构所需要的时间，包括了判断当前访问是命中还是缺失所需的时间。
>
> 缺失代价：将相应的块从低层存储器替换到高层存储器所需的时间，包括访问块，将数据逐层传输，将数据插入发生缺失的层和将信息块传递给请求者的时间。

![存储器分层](https://kuangstudy.oss-cn-beijing.aliyuncs.com/bbs/2021/04/17/kuangstudy9f6274f1-78e2-4eee-9128-ebadd29859d9.png)

&nbsp;

# 存储器技术

目前，构建存储器层次结构主要有4种技术。主存储器由**DRAM(动态随机存取存储器)实现**，靠近处理器的那层(cache)由**SRAM(静态随机存取存储器)来实现**。DRAM每比特成本要低于SRAM，但是速度比SRAM慢。价格的差异源于DRAM每比特占用的存储器空间较少，因此等量的硅制造的DRAM的容量会比SRAM的要大。速度的差异则由多种因素造成。**第三种技术是闪存**，这种非易失存储器用作个人移动设备中的二级存储器。**第四种技术是磁盘**，它通常是服务器中容量最大且速度最慢的一层。

## SRAM技术

SRAM是一种组织成存储阵列结构的简单集成电路，通常具有一个读写端口。虽然读写访问时间可能不同，但SRAM对任何数据访问时间都是固定的。

(据老师所说这是个稳定的放大电路)

![SRAM电路](https://kuangstudy.oss-cn-beijing.aliyuncs.com/bbs/2021/04/17/kuangstudy535ff802-2163-450f-a74f-b6654892c576.png)

SRAM不需要刷新，并且其访问时间与周期时间非常接近。未来防止读操作时信息丢失，SRAM的一个基本存储单元通常由6 ~ 8个晶体管组成。在空闲模式下，SRAM只需要最小的功率来保持电荷。

过去，在大多数PC和服务器系统中通常将SRAM芯片从它们的一级，二级，甚至三级cache中分离出来。由于**摩尔定律**的推动，当今的处理器芯片中集成了多层次的cache，因此独立的SRAM芯片几乎在市场上消失了。



## DRAM

在DRAM中，存储单元使用电容保存电荷的方式来存储数据。为了对保存的电荷进行读取或写入，使用一个晶体管对该电容进行访问。由于DRAM在电容上保存电荷，因此不能长久地保持数据，从而必须周期性地刷新。

![DRAM电路](https://kuangstudy.oss-cn-beijing.aliyuncs.com/bbs/2021/04/17/kuangstudy61c708f1-9283-47b9-9cfb-debb5e892d2f.png)

为了对单元进行刷新，只需要读出其中内容后写回即可。DRAM单元中的电荷可以保持几微秒。如果DRAM中的每个比特位需要独立的读出后写回，则必须不停地进行刷新操作，这将导致没有时间可以用于正常的访问操作。

幸运的是，DRAM采用了一种两级译码结构，可以通过在一个读周期后紧跟一个写周期的方式一次刷新一整行(一行单元共用一个字线)。

![DRAM逻辑结构](https://kuangstudy.oss-cn-beijing.aliyuncs.com/bbs/2021/04/17/kuangstudy1fee0462-253c-48e9-af80-4e36a2f9ddce.png)

现代DRAM以bank(存储块)方式组织。每个bank由多个行组成。发送一条Pre(预充电)命令能够打开或者关闭一个bank。使用Act(激活)命令发送一个行地址，将对应的行中的数据传送到一个缓冲器中。当一行数据在缓冲器中时，无论DRAM数据宽度(4，8，16)是多少，都可以通过指定要传送的数据块大小和数据块在缓冲器中的起始地址的方式连续传送相邻地址的数据。与数据块的传送一样，每条命令使用时钟进行同步。



为了进一步优化与处理器的接口，DRAM增加了时钟，因此称之为同步DRAM，简写为SDRAM。SDRAM的优势在于使用时钟对存储器和处理器保持同步。其速度上的优势主要源于**不需要额外指定地址位以突发方式传送多个数据的能力**(这里老师给的解释是不用发送列地址，我觉着这寻址没啥大的性能影响，从磁盘的传送时间推算。老师说这是相对于CPU的，那这个时间和磁盘的传输比没有意义)，是在时钟的控制下以突发方式传送连续的数据。最快的版本称为**双数据速率SDRAM**。**该名称表示在时钟的上升沿和下降沿都要传送数据，因此可以获得双倍的数据带宽**。



要支持如此高的带宽需要在DRAM内部进行精心组织。**与只有一个快速的行缓冲器不同，DRAM内部可以组织成对多个bank进行读或写操作，每个bank都有自己的行缓冲器。向不同的bank发送一个地址可以允许同时对它们进行读或写操作**。例如，对于4个bank而言，只需要一次访问时间，然后以轮转方式对4个bank进行控制访问就可以提供4倍带宽。这种轮转的访问方式称为**地址交叉**。

## 闪存

闪存是一种电可擦除的可编程只读存储器(EEPROM)。

与磁盘和DRAM不同，对闪存的写操作可以使存储位损耗。为了应对该限制，**大多数闪存产品都有一个控制器，用来将写操作从已经写入很多次的块中映射到写入次数较少的块中，从而使写操作尽量分散**。这种技术称为**损耗均衡**。采用损耗均衡技术，个人移动设备很难超过闪存的写极限。SSD固态硬盘就是这个通过闪存实现。



## 磁盘存储器

一个磁质硬盘包含一组圆形磁盘片，它们绕着轴心每分钟转动5400~15000周。为了对硬盘上的信息进行读写，每层的表面有一个包含小的电磁线圈的**读写磁头**。整个驱动器被永久地密封起来以控制驱动器中的环境，从而使得磁头可以距离驱动器表面非常近。

每个磁盘的表面划分为同心圆盘，称为**磁道**。每个面通常有**几万条磁道**。每条磁道同样被划分为用于存储信息的扇区。每条磁道有几千个扇区。每个扇区的容量通常是512 ~ 4096字节。信息在磁介质上保存的顺序为扇区号，一个间隙，包含该扇区纠错码的信息，一个间隙，下一个扇区的扇区号。

![磁盘](https://kuangstudy.oss-cn-beijing.aliyuncs.com/bbs/2021/04/17/kuangstudye397768b-602e-4aed-8f53-f4d7f033bb51.png)

* 磁道：位于磁盘表面的数万个同心圆环中的任意一个圆环称为一个磁道。
* 扇区：构成磁盘上磁道的基本单位，是磁盘上数据读写的最小单位。

为了访问数据，操作系统必须对磁盘进行三步操作。

1. 将磁头移动到适当的磁道之上，这称为**寻道**。将磁头移动到目标磁道所需要的时间称为**寻道时间**
2. 一旦磁头到达了正确的磁道，就要等着磁盘转动到读写头下面。这称为**旋转延时**。
3. 磁盘访问的最后一部分是**传输时间**，即传输一块数据需要的时间。

磁盘的寻址过程相对于CPU是个很慢的过程，因为其中**寻道和旋转**都是物理运动。此外这个磁盘寻道也有考究。具体的就是操作系统方面的了。篇幅原因这里不做展开。

# Cache的基本原理

处理器每次请求一个字，每个块也由一个单独的字组成。一个简单的cache类似这样：

![cache](https://kuangstudy.oss-cn-beijing.aliyuncs.com/bbs/2021/04/18/kuangstudy1d8ee2fa-2c55-4192-8976-bbde79de35ac.png)

要访问的数据项最初不在cache中。在请求前，cache中保存了最近访问过的数据项的集合，而当前处理器所要访问的数据项Xn并不在cache总。该请求导致一次缺失，Xn被从主存调入cache中。

这就引入了两个问题：

1. 怎么知道一个数据项是否在cache中？
2. 如果数据在cache中，如何找到它？

最简单的方法就是通过这个字的主存地址进行分配，这种cache结构称为**直接映射**。每个存储器地址对应到cache中一个确定的地址。对直接映射cache来说，主存地址和cache位置之间的典型映射通常比较简单。可以使用以下映射方法：

> (块地址) mod (cache中的块数)

如果cache中的块数是2的幂，取模的计算就很简单，只需要取地址的低log2位。

![cache映射](https://kuangstudy.oss-cn-beijing.aliyuncs.com/bbs/2021/04/18/kuangstudyc0c8f5bd-be9a-4714-a180-c585d29c298e.png)

由于cache中每个位置可能对应于主存中多个不同的地址，我们如何知道cache中的数据项是否是所请求的字呢？我们可以在cache中增加一组**标记**，标记中包含了地址信息，这些地址信息可以用来判断cache中的字是否就是所请求的字。**标记只需包含地址的高位**，也就是没有用来检索cache的那些位。

我们还要一种方法来判断cache中确实没有包含有效信息。也就是通过增加一个**有效位**来标识一个块是否含有一个有效地址。如果该位没有被设置就不能使用这块内容

由此我们就可以推断出cache的结构了：

![cache结构](https://kuangstudy.oss-cn-beijing.aliyuncs.com/bbs/2021/04/18/kuangstudy26e11d13-83d3-448f-ad37-0e3ed6a782ac.png)

具体的更新操作就不做详细讲解。



## cache缺失处理

> cache缺失：由于数据不在cache中而导致被请求的数据不能满足。

缺失需要做一些额外的工作。cache缺失处理由两部分共同完成：处理器控制单元，以及一个进行初始化主存访问和从新填充cache的独立控制器。**cache缺失引起流水线阻塞，这于中断不同**，中断发生时需要保存所有寄存器状态。当cache缺失，我们等待主存操作完成时，整个处理器阻塞，临时寄存器和程序员可见的寄存器中的内容基本被冻结。

那我们可以定义发生指令cache的处理步骤：

1. 把程序计数器（PC）的原始值送到存储器中。
2. 通知主存执行一次读操作，并等待主存访问完成。
3. 写cache项，将从主存取回的数据写入cache中存放数据的部分，并将地址高位写入标记域，设置有效位。
4. 重启指令执行第一步，重新取指，这次该指令在cache中。

## 写操作处理

因为cache的内容是部分主存内容的副本，应该与主存内容保持一致。而CPU对cache的写入更改了cache内容，如何与主存内容保持一致就有几种写操作工作方式可供选择，统称为写策略。

### 写直达法

又称全写法，写透。是当cache写命中时，cache与主存同时发生写修改。这种策略显然较好地维护了cache与主存的内容一致性，但这并不等于说全部解决了一致性问题。例如在多处理器系统中各CPU都有自己的cache，一个主存块若在多个cache中都有一份拷贝的话，某个CPU以写直达法来修改它的cache和主存时，其它cache中的原拷贝就过时了。即使在单处理器系统中，也有I／O设备不经过cache向主存写入的情况。总之，仍要关注一致性问题。 

当cache写未命中时，只有直接向主存写入了，但此时是否将修改过的主存块取到cache，写直达法却有两种选择。一种是取来并且为它分配一个行位置，称为WTWA法（Write--Through--with--Write--Allocate）。另一种是不取称为WTNWA法（WriteThrough--with．NO-Write--Allocate）。前 一种方法保持了cache / 主存的一致性，但操作复杂，而后一种方法操作简化，但命中率降低，内存的修改块只有在读未命中对cache 进行替换时，才有可能映射到cache 。 

写直达法是写cache与写主存同步进行，其优点是cache每行无需设置一个修改位以及相应的判测逻辑。写直达法的缺点是，cache对CPU向主存的写操作无高速缓冲功能，降低了cache的功效。 

### 写回法

当CPU对cache写命中时，只修改cache的内容不立即写入主存，只当此行被换出时才写回主存。这种策略使cache在CPU－主存之间，不仅在读方向而且在写方向上都起到高速缓存作用。对一cache行的多次写命中都在cache中快速完成修改， 只是需被替换时才写回速度较慢的主存，减少了访问主存的次数从而提高了效率。为支持这种策略，每个cache行必须配置一个修改位，以反映此行是否被CPU修改过。当某行被换出时，根据此行修改位为1还是为0，决定是将该行内容写回主存还是简单地弃之 而不顾。 

对于cache写未命中，写回法的处理是为包含欲写字的主存块在cache分配一行，将此块整个拷贝到Cache后对其进行修改， 因为尔后对此块的多次读/写访问的可能性很大。拷贝主存块时虽已读访问到主存，但此时并不对主存块修改。因为换出的cache很可能此期间要写回主存，为避免此过程耗时太长，写未命中对将新块读入后，只在cache中进行写修改。统一地将主存写修改操作留待换出时进行。 

这种写cache与写主存分开进行方式可显著减少写主存次数，但写回法也带来了cache 主存严重的不一致性。**MESI协议就是针对写回法的维护cache一致性的协议。到Java才有volatile和happen-before原则**。

### 写一次法

写一次法是一种基于写回法又结合了写直达法的写策略，即写命中和写未命中的处理与写回法基本相同，只是第一次写命中时要同时写入主存。这种策略主要用于某些处理器的片内cache，例如Pentium处理器的片内数据cache就采用的是写一次 法。因为片内cache写命中时，写操作就在CPU内部高速完成，若没有 内存地址及其它指示信号送出，就不便于系统中的其它cache监听（snoop）。采用写一次法，在第一次片内cache写命中时， CPU要在总线上启动一个存储写周期。其它cache监听到此主存块地址及写信号后，即可把它们各自保存可能有的该块拷贝及时作废（无效处理）。尔后若有 对片内cache此行的再次或多次写命中，则按回写法处理，无需再送出信号了。这样虽然第一次写命中时花费了一个存 储周期，但对维护系统全部cache的一致性有利。而大多的cache写操作不涉及到片外，对指令流水执行有利



参考资料：

《计算机组成与设计 硬件/软件接口》

《深入理解计算机系统》

https://blog.csdn.net/zhuliting/article/details/6210993
